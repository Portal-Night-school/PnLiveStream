from aiogram import Router, F
from aiogram.types import Message, CallbackQuery, FSInputFile
from keyboards import stop_context, start_keyboard, rmk
from collections import defaultdict
from google.generativeai import configure, GenerativeModel
from dotenv import load_dotenv
import base64
import os
import re
from aiogram.utils import markdown
from openai import OpenAI
from kandinsky import Kandinsky
from aiogram.fsm.state import State, StatesGroup
from aiogram.fsm.context import FSMContext
from aiogram.utils.chat_action import ChatActionSender
from main import bot
from aiogram.enums import ParseMode

load_dotenv()


rt = Router()
GEMINI_API_KEY=os.getenv('GEMINI_API_KEY')
DEEPSEEK_API_KEy = os.getenv('DEEPSEEK_API_KEY')

class chatKandin(StatesGroup):
    kandinski_chat = State()


client_deepseek = OpenAI(api_key=DEEPSEEK_API_KEy, base_url="https://api.deepseek.com")


configure(api_key=GEMINI_API_KEY)
model_gemini = GenerativeModel("models/gemini-1.5-flash")

user_session = defaultdict(lambda: None)
user_context = defaultdict(list)


async def get_deepseek_response(user_id):
    try:
        response = client_deepseek.chat.completions.create(
            model="deepseek-chat",
            messages=user_context[user_id]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}"



async def get_gemini_response(user_id):
    try:
        messages = [
            {"role": "user", "parts": [msg["content"]]} if msg["role"] == "user"
            else {"role": "model", "parts": [msg["content"]]}
            for msg in user_context[user_id]
        ]
        response = model_gemini.generate_content(messages)
        return response.text if response else "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞"
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}"


@rt.message(F.text == "üê≥ DeepSeek")
async def start_deepseek(msg: Message):
    user_session[msg.from_user.id] = 'deepseek'
    await msg.answer("–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –¥–ª—è DeepSeek", reply_markup=stop_context)


@rt.message(F.text == '‚ú® Gemini')
async def start_gemini(msg: Message):
    user_session[msg.from_user.id] = "gemini"
    await msg.answer("–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –¥–ª—è Gemini", reply_markup=stop_context)
    
# –≤—Ä–µ–º–µ–Ω–Ω–æ
@rt.message(F.text == 'üñºÔ∏è Kandinsky')
async def start_kandinsky(msg: Message, state: FSMContext):
    await msg.answer("–í—Ä–µ–º–µ–Ω–Ω–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –æ—Ç–∫–ª—é—á–µ–Ω–∞")
    
'''
@rt.message(F.text == 'üñºÔ∏è Kandinsky')
async def start_kandinsky(msg: Message, state: FSMContext):
    global descr 
    descr = await msg.answer("–ù–∞–ø–∏—à–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏", reply_markup=rmk)
    await state.set_state(chatKandin.kandinski_chat)
''' 
    
@rt.message(chatKandin.kandinski_chat)
async def send_picture(msg: Message, state: FSMContext):
    # await descr.delete()
    async with ChatActionSender(bot=bot, chat_id=msg.from_user.id, action="upload_video"):
        processing_message = await msg.answer("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∑–∞–Ω–∏–º–∞–µ—Ç –æ—Ç 30 —Å–µ–∫\.\.\.")
        prompt = msg.text
        api = Kandinsky()
        uuid = api.generate(prompt)
        images = api.check_generation(uuid)
        if images:
            image_base64 = images[0]
            image_data = base64.b64decode(image_base64)
            
            dir = f"./media/{uuid}.jpg"
            with open(dir, "wb") as file:
                file.write(image_data)
            
            file = FSInputFile(dir)
            caption = f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ –∑–∞–ø—Ä–æ—Å—É:\n{msg.text}\n—Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ!\n\n–ú–æ–∂–µ—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"
            formatted_response = markdown.text(
                markdown.markdown_decoration.quote(
                    caption
                )
            )
            await msg.delete()
            await processing_message.delete()
            await msg.answer_photo(photo=file, caption=formatted_response, reply_markup=stop_context, parse_mode=ParseMode.MARKDOWN)
            os.remove(dir)
        else:
            await msg.answer("–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫, –ø—Ä–æ–±—É—é –µ—â–µ —Ä–∞–∑")
    

    
@rt.callback_query(F.data == 'stop')
async def clear_context(call: CallbackQuery):
    user_session[call.message.from_user.id] = None
    await call.message.answer("–í—ã –∑–∞–∫–æ–Ω—á–∏–ª–∏ –¥–∏–∞–ª–æ–≥", reply_markup=start_keyboard)
    

@rt.callback_query(F.data == "stop_generation")
async def stop_generation_images(call: CallbackQuery, state: FSMContext):
    await state.clear()
    await call.message.answer("–í—ã –≤ –≥–ª–∞–≤–Ω–æ–º –º–µ–Ω—é", reply_markup=start_keyboard)
    
    
@rt.message()
async def handle_neuro(msg: Message):
    user_id = msg.from_user.id 
    model = user_session[user_id]
    
    if model is None:
        await msg.answer(
            "–í—ã–±–µ—Ä–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–¥–Ω—É –∏–∑ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π",
            parse_mode=ParseMode.MARKDOWN
        )
        return
    
    processing_message = await msg.answer(
        "–ù–µ–π—Ä–æ—Å–µ—Ç—å –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å... ‚è∞",
        reply_markup=rmk,
        parse_mode=ParseMode.MARKDOWN
    )
    
    user_context[user_id].append({"role": "user", "content": msg.text})
    
    if model == 'deepseek':
        response = await get_deepseek_response(user_id)
    elif model == "gemini":
        response = await get_gemini_response(user_id)
    else:
        response = "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å"
    
    user_context[user_id].append({"role": "assistant", "content": response})
    print(response)

    # –ó–¥–µ—Å—å –¥–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –æ—á–∏—Å—Ç–∫—É –æ—Ç –∑–∞–ø—Ä–µ—â—ë–Ω–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
    formatted_response = response
    await processing_message.delete()
    await msg.answer(
        formatted_response,
        reply_markup=stop_context,
        parse_mode=ParseMode.MARKDOWN
    )